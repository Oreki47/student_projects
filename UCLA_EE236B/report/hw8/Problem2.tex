\subsection*{A4.25}
\paragraph{}
First we can write its equivalence,
\begin{align*}
&\text{minimize}\qquad \sum_{i=1}^{n}\alpha_i \log(\sum_{j=1}^{n}A_{ij}x_j)\\
&\text{subjct to}\qquad \sum_{i=1}^{n} \alpha_i \log x_i =0
\end{align*}
\paragraph{}
Thus, the Lagrangian can be formed as:
\begin{align*}
L(x, z) = \sum_{i=1}^{n}\alpha_i \log(\sum_{j=1}^{n}A_{ij}x_j) + z\sum_{i=1}^{n} \alpha_i \log x_i
\end{align*}
\paragraph{}
Since this is differential over $x$, we take the partial to $x_k$ and have
\begin{align*}
\sum_{i=1}^{n} \alpha_i\frac{A_{ik}x_k}{\sum_{j=1}^{n}A_{ij}x_j} = \alpha_k z, \qquad k=1,...,n
\end{align*}
\paragraph{}
summing up $k =1,...,n$ and we have
\begin{align*}
\sum_{k=1}^{n}\sum_{i=1}^{n} \alpha_i\frac{A_{ik}x_k}{\sum_{j=1}^{n}A_{ij}x_j} =\sum_{i=1}^{n} \alpha_i\frac{\sum_{k=1}^{n}A_{ik}x_k}{\sum_{j=1}^{n}A_{ij}x_j}  =\sum_{k=1}^{n}\alpha_k z
\end{align*}
\paragraph{}
Therefore, $z =1$. and we have
\begin{align*}
\sum_{i=1}^{n} \alpha_i\frac{A_{ik}x_k}{\sum_{j=1}^{n}A_{ij}x_j} = \alpha_k, \qquad k =1,...,n
\end{align*}
\paragraph{}
Or in vector form,
\begin{align*}
\text{diag}(Ax)^{-1}\text{diag}(x)A^T \alpha = \alpha
\end{align*}
\paragraph{}
For the original equation, we have
\begin{align*}
&(D_1AD_2)^Tv = D_2A^TD_1v = \text{diag}(u)^{-1}\text{diag}(x)A^T\text{diag}(u)\text{diag}(Ax)^{-1}v\\
&\qquad \qquad \qquad \qquad \qquad \ \ =\text{diag}(u)^{-1}\text{diag}(Ax)^{-1}\text{diag}(x)A^T \alpha \\
&\qquad \qquad \qquad \qquad \qquad \ \ = \text{diag}(u)^{-1} \alpha \\
&\qquad \qquad \qquad \qquad \qquad \ \ = v
\end{align*}